{"name":"Make Me a Hanzi","tagline":"Free, open-source Chinese character data","body":"### Introducing Make Me a Hanzi\r\n\r\nChinese characters, or hanzi, feature a rich structure. This structure offers clues into the history and meaning of different characters, and understanding it is a key step to learning to read and write. Many organizations have data about the structure of hanzi. For example, [Wiktionary](https://en.wiktionary.org/wiki/%E5%AD%97) and [CJKlib](https://github.com/cburgmer/cjklib) have character decomposition data; [Unihan](http://unicode.org/charts/unihan.html) provides information about their meaning and pronunciation; and the [Wikimedia Stroke Order Project](https://commons.wikimedia.org/wiki/Commons:Stroke_Order_Project) produced stroke order data for about a thousand of the most common characters.\r\n\r\nUnfortunately, much of the best data about hanzi is proprietary. Apple's phones include an excellent Chinese keyboard that is based on stroke vector data, and [Skritter](https://www.skritter.com/login) uses similar data for its writing lessons. A number of websites have independently compiled stroke order graphics of varying coverage and quality.\r\n\r\nI started working on Make Me a Hanzi when I realized that it was possible to extract much of this data from the raw characters themselves. This project uses a variety of heuristic and trained methods to derive stroke position and order information directly from two free, open-source Chinese fonts - [Arphic PL KaitiM GB](https://apps.ubuntu.com/cat/applications/precise/fonts-arphic-gkai00mp/) and [Arphic PL UKai](https://apps.ubuntu.com/cat/applications/fonts-arphic-ukai/). In addition, I reviewed the definition and pronunciation data from Unihan and the decomposition data from CJKlib and used them to build a new set of etymological data.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}