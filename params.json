{"name":"Make Me a Hanzi","tagline":"Free, open-source Chinese character data","body":"### Show me what you got!\r\n\r\nMake Me a Hanzi provides dictionary and graphical data for over 9000 of the most common simplified and traditional Chinese characters. Among other things, this data includes stroke-order vector graphics for all these characters. You can see the project output at [the demo site](http://www.makemeahanzi.mod.bz), where you can look up a characters by drawing them. You can also download the data for use in your own site or app.\r\n\r\n### Motivation\r\n\r\nChinese characters, or hanzi, feature a rich structure. This structure offers clues into the history and meaning of different characters, and understanding it is a key step to learning to read and write. Many organizations have data about the structure of hanzi. For example, [Wiktionary](https://en.wiktionary.org/wiki/%E5%AD%97) and [CJKlib](https://github.com/cburgmer/cjklib) have character decomposition data; [Unihan](http://unicode.org/charts/unihan.html) provides information about their meaning and pronunciation; and the [Wikimedia Stroke Order Project](https://commons.wikimedia.org/wiki/Commons:Stroke_Order_Project) produced stroke order data for about a thousand of the most common characters.\r\n\r\nUnfortunately, much of the best data about hanzi is proprietary. Apple's phones include an excellent Chinese keyboard that is based on stroke vector data, and [Skritter](https://www.skritter.com/login) uses similar data for its writing lessons. A number of websites have independently compiled stroke order graphics of varying coverage and quality.\r\n\r\nI started working on Make Me a Hanzi when I realized that it was possible to extract much of this data from the raw characters themselves. This project uses a variety of heuristic and trained methods to derive stroke position and order information directly from two free, open-source Chinese fonts - [Arphic PL KaitiM GB](https://apps.ubuntu.com/cat/applications/precise/fonts-arphic-gkai00mp/) and [Arphic PL UKai](https://apps.ubuntu.com/cat/applications/fonts-arphic-ukai/). In addition, I reviewed the definition and pronunciation data from Unihan and the decomposition data from CJKlib and used them to build a new set of etymological data.\r\n\r\n### Usage\r\n\r\nThe README.md file included with the data set has a detailed specification of the data format. In addition, you may find the [libraries used in the demo site](https://github.com/skishore/makemeahanzi/tree/demo/lib) useful. These libraries include a handwriting recognition algorithm and a utility for drawing a stroke-order animation, and they are all released into the public domain.\r\n\r\n### Next steps\r\n\r\nThere's a lot that can be done with this data. Here are a few ideas that you might be inspired by:\r\n- Render the stroke order for each character to an animated GIF.\r\n- Create a free and open-source \"learn to write characters\" app.\r\n- Use the etymology data for science! \"Is the left component more likely to be phonetic than the right one?\"\r\n\r\nAs for me, I plan to make more corrections to the data, to build out nice APIs for using it, and to write some follow-up posts that explain how Make Me a Hanzi's font-to-stroke-order algorithms work.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}