<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Make Me a Hanzi by skishore</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Make Me a Hanzi</h1>
        <p>Free, open-source Chinese character data</p>

        <p class="view"><a href="https://github.com/skishore/makemeahanzi">View the Project on GitHub <small>skishore/makemeahanzi</small></a></p>


        <ul>
          <li><a href="https://github.com/skishore/makemeahanzi/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/skishore/makemeahanzi/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/skishore/makemeahanzi">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h3>
<a id="show-me-what-you-got" class="anchor" href="#show-me-what-you-got" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Show me what you got!</h3>

<p>Make Me a Hanzi provides dictionary and graphical data for over nine thousand of the most common simplified and traditional Chinese characters. The data is divided between two files: dictionary.txt, which includes definitions, decompositions, and etymologies, and graphics.txt, which includes stroke positions and orders. The first file is derived from Unihan and CJKlib and licensed under the GNU Lesser Public License, while the latter file is derived from two of Arphic Technology's fonts and licensed under the Arphic Public License.</p>

<p>For a specification of the format of these files, please see the included documentation.</p>

<p>In addition, I have built <a href="http://www.makemeahanzi.mod.bz">a demo site that makes use of both datasets</a>. On this site, you can look up a character by drawing it, and you can report an error on an individual character's page by clicking the red X mark.</p>

<h3>
<a id="motivations" class="anchor" href="#motivations" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Motivations</h3>

<p>Chinese characters, or hanzi, feature a rich structure. This structure offers clues into the history and meaning of different characters, and understanding it is a key step to learning to read and write. Many organizations have data about the structure of hanzi. For example, <a href="https://en.wiktionary.org/wiki/%E5%AD%97">Wiktionary</a> and <a href="https://github.com/cburgmer/cjklib">CJKlib</a> have character decomposition data; <a href="http://unicode.org/charts/unihan.html">Unihan</a> provides information about their meaning and pronunciation; and the <a href="https://commons.wikimedia.org/wiki/Commons:Stroke_Order_Project">Wikimedia Stroke Order Project</a> produced stroke order data for about a thousand of the most common characters.</p>

<p>Unfortunately, much of the best data about hanzi is proprietary. Apple's phones include an excellent Chinese keyboard that is based on stroke vector data, and <a href="https://www.skritter.com/login">Skritter</a> uses similar data for its writing lessons. A number of websites have independently compiled stroke order graphics of varying coverage and quality.</p>

<p>I started working on Make Me a Hanzi when I realized that it was possible to extract much of this data from the raw characters themselves. This project uses a variety of heuristic and trained methods to derive stroke position and order information directly from two free, open-source Chinese fonts - <a href="https://apps.ubuntu.com/cat/applications/precise/fonts-arphic-gkai00mp/">Arphic PL KaitiM GB</a> and <a href="https://apps.ubuntu.com/cat/applications/fonts-arphic-ukai/">Arphic PL UKai</a>. In addition, I reviewed the definition and pronunciation data from Unihan and the decomposition data from CJKlib and used them to build a new set of etymological data.</p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/skishore">skishore</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
